---
title: "DataProcessing"
author: "Alex van den Berg"
output:
  html_document:
    toc: true
    theme: united
    highlight: tango
date: "`r Sys.Date()`"
runtime: shiny
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(data.table)
library(RColorBrewer)
library(ggplot2)
library(ggpubr)
library(plyr)
library(dplyr)
library(readxl)
library(rstatix)
library(plotrix)
library(car)
library(Rmisc)
#library(ggrepel)

# boxplots?
library(tidyr)
#library(tidyverse)
library(devtools)
library(ggpattern) # To differentiate when printing in black and white
  # install.packages("devtools")
  # devtools::install_github("coolbutuseless/ggpattern")
  # make sure RTools is installed: https://cran.r-project.org/bin/windows/Rtools/rtools42/rtools.html

#LMER stuff
library(lme4)
library(emmeans)
library(sjstats)
library(lmerTest)
library(MuMIn)

# saving figures
library(svglite)

# File importing / reading
library(jsonlite) # for json files

# Reshaping data for questionnaires
library(reshape2)

# For the rotation matrices
library(geometry)

# For the filtering of the artefacts
library(zoo)

# Interactive 3D plots
library(rgl)
```

(Optional) clear the environment
```{r}
rm(list=ls())  # clear objects
cat("\014")  # clear console
```

# Loading in the Data
Loading done with help of chatgpt-4.0, see chat [here](https://chat.openai.com/share/e776898f-356f-4b5b-8d75-656ed7fd7a6f).

## Obtaining the paths & participant details

First, we get list of all participants, which are saved into folders in data directory.

```{r}
dataFolder = file.path(".","data")
participants = list.dirs(path = dataFolder, full.names = FALSE, recursive = FALSE)
participants

getPdir = function(pnum){ 
  return(file.path(dataFolder, pnum))
}

#getPdir(participants[1]) # example usage
```

The experimental conditions are saved in terms of the [UXF settings](https://github.com/immersivecognition/unity-experiment-framework/wiki). In the settings file, one of the parameters: `first` determined whether the VFD condition was done first (`first==TRUE`) or second (`first==FALSE`). 

We will also need the participant details from this same folder, which include the demographic data

```{r}
getPsettingsFile = function(pnum){ 
  return(file.path(getPdir(pnum),"session_info","settings.json"))
}

# If true, the participant started with noise VFD enabled, otherwise without it enabled
getPsetting <- function(pnum, settingName) {
  # get the path to the settings file for the participant
  settingsFile <- getPsettingsFile(pnum)
  # read the json file into a list
  settings <- jsonlite::fromJSON(settingsFile)
  
  # retrieve the value of the specific detail
  settingValue <- settings[[settingName]][1]
  
  return(settingValue)
}

# If true, the participant started with noise VFD enabled, otherwise without it enabled
startedWithNoise <- function(pnum) {
  return(getPsetting(pnum,"first"))
}

#startedWithNoise(participants[1])

getPdetail <- function(pnum, detailName) {
  # get the path to the details file for the participant
  detailsFile <- file.path(getPdir(pnum),"session_info","participant_details.csv")
  
  # read the csv file into a data frame
  details <- read.csv(detailsFile)
  
  # retrieve the value of the specific detail
  detailValue <- details[[detailName]][1]
  
  return(detailValue)
}

#getPdetail(participants[1],"age") # example usage
```

## Get the tracking data

We'll need the paths to the [trackers](https://github.com/immersivecognition/unity-experiment-framework/wiki/Data-collection). Which contain all the data which is tracked for each of the trials. The same tracker names are used for each participant for each session (condition in this case), so we'll just get a list we can refer back to later. Additionally, we'll define another function to get a certain tracker dataset for a selected participant.

```{r}
trackerPath = file.path(getPdir(participants[1]),"trackers")
trackers = list.files(path = trackerPath, full.names = FALSE)
trackers # use one of the participants to get the different file names for all the tracker files.

# we make a list of the filenames so we can easily call them without writing the whole filename
filenameDict <- list(
  "leftfoot" = "leftfoot_tracker_movement_T",
  "loko_lokodata" = "loko_lokodata_T",
  "rightfoot" = "rightfoot_tracker_movement_T",
  "tmleft" = "tmleft_tracker_movement_T",
  "tmright" = "tmright_tracker_movement_T",
  "vivetrackers" = "vivetrackers_SteamVRData_T"
)

# get any type of data
getTdata <- function(pnum, trackerType, trialNumber) {
  
  # Construct filename from filenamePattern and participantNumber
  filename <- paste0(filenameDict[[trackerType]], sprintf("%03d", trialNumber), ".csv")
  
  # Construct full file path
  filePath <- file.path(getPdir(pnum),"trackers",filename)
  
  # Check if the file exists
  if(!file.exists(filePath)) {
    stop("The specified file does not exist.")
  }
  
  # Read the data from the csv file
  data <- read.csv(filePath)
  
  return(data)
}

#getTdata(participants[1],"leftfoot",TRUE) # example usage
```


## Get the Questionnaire data
The questionnaire data is in a separate file. First, we write some methods to extract the data.
```{r}
questionnaireInfoFolder = file.path(".","questionnaires")

getQfile = function(pnum,qType){ # qType = IMI / SSQ / VEQ
  return(file.path(getPdir(pnum),"questionnaires",paste0("questionnaireID_",qType,"_ALL_answers.csv")))
}

getQdata <- function(pnum) {
  # Get the path to the questionnaire file for the participant
  questionnaireFile <- getQfile(pnum, "disturbanceExperiment")
  
  # Read the CSV file into a data frame
  questionnaire <- read.csv(questionnaireFile)
  
  # Identifying the columns with answers
  answerColumns <- grep("Answer_", names(questionnaire), value = TRUE)
  
  # Dynamically extract and label the data based on trial numbers
  result <- data.frame(QuestionID = questionnaire$QuestionID)
  for (i in seq_along(answerColumns)) {
    columnName <- paste0("Trial_", i)
    result[[columnName]] <- questionnaire[[answerColumns[i]]]
  }
  
  return(result)
}


#getQdata(participants[1])# example usage
```
We extract this data and calculate some resulting scores each questionnaire. We then add the questionnaire data to our distances data table.

First, we define a method to extract some info about the questionnaires, and then use that info to calculate the scores for a specific participants and questionnaire:

```{r}
getQuestionInfo <- function(qType) { # qType = IMI / SSQ / VEQ
  qInfopath = file.path(questionnaireInfoFolder,paste0(qType,".csv"))
  # Read the CSV file into a data frame
  questionnaire <- read.csv(qInfopath)
  return(questionnaire)
}

computeScores <- function(pnum) {
  qdata = getQdata(pnum)
  
  qinfo = getQuestionInfo("disturbanceExperiment")
  combined <- merge(qdata, qinfo, by = "QuestionID")

  # Find trial columns
  trialColumns <- grep("Trial_", names(combined), value = TRUE)

  # Initialize an empty list to store scores for each trial
  allScores <- list()

  # Loop through each trial column to calculate scores
  for (trialCol in trialColumns) {
    # Mirror the scores if needed
    combined[[trialCol]] <- ifelse(combined$mirror, 8 - combined[[trialCol]], combined[[trialCol]])

    # Compute the scores for each category for the trial
    scoresTrial <- tapply(combined[[trialCol]], combined$category, mean, na.rm = TRUE)

    # Compute the total score for the trial
    scoresTrial["total"] <- mean(scoresTrial, na.rm = TRUE)
    
    # Store the calculated scores in the list
    allScores[[trialCol]] <- scoresTrial
  }
  
  return(allScores)
}

#computeScores(participants[1])# example usage
```

Now we can use this method to make a dataframe to get all scores for all the participants.

```{r}
calculateAllScores <- function(participants) {
  # Initialize an empty list to hold results for each trial
  allScores <- list()

  # Iterate over the participants
  for (participant in participants) {
    # Compute the scores for the participant
    participantScores <- computeScores(participant)
    
    # Iterate over each trial's scores
    for (trial in names(participantScores)) {
      trialScores <- participantScores[[trial]]

      # Transform the scores into a data frame with a single row and bind it with the participant ID
      trialRow <- cbind(participant = participant, as.data.frame(t(trialScores)))

      # If the trial doesn't exist in allScores, initialize it
      if (!trial %in% names(allScores)) {
        allScores[[trial]] <- data.frame()
      }

      # Add the scores to the corresponding trial in allScores
      allScores[[trial]] <- rbind(allScores[[trial]], trialRow)
    }
  }
  
  # Reshape and combine all trials' data
  combinedData <- do.call(rbind, lapply(names(allScores), function(trial) {
    cbind(Trial = trial, allScores[[trial]])
  }))
  
  return(combinedData)
}

#calculateAllScores(participants) # example use
```


# Pre-processing

## Extract trial data
We first find the start and end times for each trial and each participant

```{r}
findTrialTimes <- function(participant, trialNumber) {
  # Retrieve trial start and end times from loko_lokodata
  lokoData <- getTdata(participant, "loko_lokodata", trialNumber)
  
  # Identifying the index where trialStarted turns to 1
  startIndex <- which(lokoData$trialStarted == 1)[1]
  
  # Identifying the index where trialStarted turns back to 0
  endIndex <- tail(which(lokoData$trialStarted == 1), 1) # this grabs the last time this happens, if there are multiple trials within the same datafile (which shouldn't happen), this is not accounted for

  # Extracting time and Lokotime at the start and end of the trial
  trialStartTime <- lokoData$time[startIndex]
  trialStartLokotime <- lokoData$Lokotime[startIndex]
  trialEndTime <- lokoData$time[endIndex]
  trialEndLokotime <- lokoData$Lokotime[endIndex]

  # Save the start and end times for later use or analysis
  trialTimes <- data.frame(
    Start_Time = trialStartTime, 
    Start_Lokotime = trialStartLokotime,
    End_Time = trialEndTime,
    End_Lokotime = trialEndLokotime
  )
  
  return(trialTimes)
}

# Example usage
#findTrialTimes(participants[1], 1)
```

## Tracker data

All tracker data is recorded in the vivetracker csv. The others are just for backup but aren't used right now. We extract the relevant data by matching the timepoints in the lokodata.

```{r}
getTrackerDataForTrial <- function(participant, trialNumber, startTime = 0, endTime = 130) {
  # Retrieve the trial times using findTrialTimes
  trialTimes <- findTrialTimes(participant, trialNumber)
  
  # Get the tracker data
  data <- getTdata(participant, "vivetrackers", trialNumber)
  
  # Filter the tracker data based on trial start and end times
  data <- data[
    data$time >= trialTimes$Start_Time & data$time <= trialTimes$End_Time, 
  ]
  
  # Replace recording time ("time") with real, more accurate, time of the recording thread ("systemTime")
  data$time = data$systemTime
  data$systemTime<- NULL
  
  # Adjust time so its relative to the first sample
  data$time <- data$time - data$time[1]
  
  # We use this for filtering artifacts later
  data$artifact <- "none" # fill it first
  
  # For some reason there sometimes are duplicate rows, we filter those out here
  data <- data %>% distinct()
  
  return(data)
}

# Example usage
trackerData <- getTrackerDataForTrial(participants[1], 1)
#trackerData
```

# Post-processing
We need to filter and transform our data before we can extract the gait parameters.

## Filtering artefacts
First, we filter out artefacts from our dataset (points at which the trackers disconnected). We identify these by using two methods:
- One of the components is equal to zero (this almost only happens when a tracker disconnects).
- A threshold velocity is passed. Points at which the trackers shoot away from one frame to the next.

```{r}
# For interpolation quaternions
slerp <- function(q1, q2, t) {
    cosTheta <- sum(q1 * q2)
    if (cosTheta < 0) {
        q1 <- -q1
        cosTheta <- -cosTheta
    }

    if (cosTheta > 0.95) {
        # If the quaternions are very close, linearly interpolate and normalize the result
        result <- (1 - t) * q1 + t * q2
        return(result / sqrt(sum(result * result)))
    }

    theta <- acos(cosTheta)
    sinTheta <- sqrt(1 - cosTheta * cosTheta)

    return((sin((1 - t) * theta) * q1 + sin(t * theta) * q2) / sinTheta)
}

interpolateQuaternions <- function(data, quatCols, artifact_indices) {
  if (length(artifact_indices) == 0) {
      return(data) # No artifacts to interpolate
  }
  
  
  
  ### Interpolating this data takes too much compute, but we don't need rotations anyway so lets ignore this problem for now.
  data[, quatCols] <- na.approx(data[, quatCols])
  return(data)
  ### For now, we do linear interpolation, which is way faster but not actually accurate
  
  n <- nrow(data)
  artifact_indices <- sort(unique(artifact_indices)) # Ensure indices are sorted and unique
  artifact_diffs <- c(1, diff(artifact_indices), 1) # Differences, with padding for first and last indices

  # Identify starts and ends of artifact sequences
  starts <- artifact_indices[artifact_diffs[-length(artifact_diffs)] > 1]
  ends <- artifact_indices[artifact_diffs[-1] > 1]
  if (length(starts) == 0 || length(ends) ==0){
    starts <- artifact_indices[1]
    ends <- artifact_indices[length(artifact_indices)]
  }
  
  # Include the first artifact index in starts and the last in ends if not already included
  if (artifact_indices[1] != starts[1]) {
      starts <- c(artifact_indices[1], starts)
  }
  if (tail(artifact_indices, 1) != tail(ends, 1)) {
      ends <- c(ends, tail(artifact_indices, 1))
  }

  for (i in seq_along(starts)) {
      startIdx <- starts[i]
      endIdx <- ends[i]
      # Find nearest non-artifact indices
      prevIdx <- if (startIdx > 1) max(1, startIdx - 1) else NA
      nextIdx <- if (endIdx < n) min(n, endIdx + 1) else NA
      
      # Interpolate if valid indices are found
      if (!is.na(prevIdx) && !is.na(nextIdx)) {
          q1 <- data[prevIdx, quatCols]
          q2 <- data[nextIdx, quatCols]
          for (j in startIdx:endIdx) {
              t <- (j - prevIdx) / (nextIdx - prevIdx)
              data[j, quatCols] <- slerp(q1, q2, t)
          }
      }
  }

  return(data)
}

filterArtifacts <- function(data, trackerName, velocity_threshold = 10, rotational_velocity_threshold = 3, passes = 1) { # velocity_threshold in m/s , rotational_velocity_threshold in rad/s
  pattern <- paste0("^", trackerName) # get just the position data
  trackerCols <- grep(pattern, colnames(data), value = TRUE) # Get the column names that match the pattern
  posCols <- grep(".pos", trackerCols, value = TRUE) # only the position columns (these are used to get the velocity)
  quatCols <- grep(".rot", trackerCols, value = TRUE) # Quaternion columns

  if (length(posCols) != 3 || length(quatCols) != 4) {
      stop("Error: Incorrect number of position or quaternion columns.")
  }
  
  tempData <- data
  artifact_indices <- c()
  
  # Check if any component is exactly zero, mark as artifact
  THRESHOLD = 0.00001
  for (col in trackerCols) {
    artifact_indices <- c(artifact_indices, which(abs(tempData[[col]]) == 0))
  }
  artifact_indices <- sort(unique(artifact_indices))
  
  data$artifact[artifact_indices] <- trackerName # mark the datapoints
  
  tempData[artifact_indices, trackerCols] <- NA
  # we want to filter the missing data before checking the big jumps
  tempData[, posCols] <- na.approx(tempData[, posCols]) # approx position
  tempData <- interpolateQuaternions(tempData, quatCols, artifact_indices) # approx rotation
  
  for (i in 1:passes) {
    # Calculate positional differences
    diffs <- data.frame(lapply(data[, posCols], function(col) c(NA, diff(col))))
    names(diffs) <- paste0("diff_", posCols)
    diffs$diff_time <- c(NA, diff(data$time))
    
    # Calculate quaternion differences and rotational velocity
    quat_current <- tempData[, quatCols]
    quat_next <- rbind(quat_current[-1, ], rep(NA, length(quatCols)))
    dot_product <- rowSums(quat_current * quat_next, na.rm = FALSE)
    
    # Clamping dot product within the range [-1, 1] to avoid NaNs
    dot_product <- pmin(pmax(dot_product, -1), 1)
    rotational_diff <- 2 * acos(dot_product)
    rotational_velocity <- c(NA, rotational_diff[-1] / diffs$diff_time[-1])  # Skip first and align lengths

    # Combine diffs with data and calculate linear velocity
    tempData <- cbind(data, diffs)
    tempData$distance <- sqrt(rowSums(tempData[, paste0("diff_", posCols)]^2))
    tempData$velocity <- tempData$distance / tempData$diff_time
    tempData$rotational_velocity <- rotational_velocity
      
    # Identify velocity artifacts
    velocity_artifact_indices <- which(tempData$velocity > velocity_threshold)
    rotational_velocity_artifact_indices <- which(tempData$rotational_velocity > rotational_velocity_threshold)
    combined_artifact_indices <- unique(c(velocity_artifact_indices, rotational_velocity_artifact_indices))
    
    # Mark artifacts
    data$artifact[combined_artifact_indices] <- trackerName
    #print(rotational_velocity_artifact_indices)
    # Interpolate
    tempData[combined_artifact_indices, trackerCols] <- NA
    tempData[, posCols] <- na.approx(tempData[, posCols])
    tempData <- interpolateQuaternions(tempData, quatCols, combined_artifact_indices) 
  }
  
  data[, trackerCols] <- tempData[, trackerCols]
  
  return(data)
}

#filterArtifacts(trackerData, "TreadmillLeft") # example usage

filterAllData <- function(data, velocity_threshold = 10, rotational_velocity_threshold = 100, passes = 1) {
  # Process and filter each dataset with a unique artifact label  --> Note, if 2 datasets both have an artefact at the same time frame, only the last one here will be saved.
  data <- filterArtifacts(data, "TreadmillLeft", velocity_threshold, rotational_velocity_threshold, passes)
  data <- filterArtifacts(data, "TreadmillRight", velocity_threshold, rotational_velocity_threshold, passes)
  data <- filterArtifacts(data, "LeftFoot", velocity_threshold, rotational_velocity_threshold, passes)
  #data <- filterArtifacts(data, "RightFoot", velocity_threshold, rotational_velocity_threshold, passes)
  
  return(data)
}

# Usage example:
filteredData <- filterAllData(trackerData, 10, 50, 1)
#filteredData[filteredData$artifact != "none",]
```

### Select data to plot
Select what data to plot for the trajectory plots.

```{r, echo=FALSE}
inputPanel(
  selectizeInput("participant", "Participant", 
                choices = participants, selected = participants[1], multiple = FALSE),
  numericInput("TrialNumber", "Trial Number", 
                min = 1, max = Inf, value = 1, step = 1),
  numericInput("start", "Start Time",
              min = 0, max = 500, value = 0, step = 1),
  numericInput("end", "End Time",
              min = 0, max = 500, value = 120, step = 1)
)
```

### 2D Plot
We plot our data in 2D to check our filtered datapoints to make sure we are not discarding important data. Play with the max velocity by which the data is filtered.

```{r,echo=FALSE}
posCols <- grep(".pos", colnames(trackerData), value = TRUE)
rotCols <- grep(".rot", colnames(trackerData), value = TRUE)
xOptions = c("time", posCols, rotCols)

inputPanel(
  selectizeInput("xplot", "X-axis", 
                choices = xOptions, selected = xOptions[1], multiple = FALSE),
  selectizeInput("yplot", "Y-axis", 
                choices = xOptions, selected = xOptions[2], multiple = FALSE),
  numericInput("maxv", "Max velocity (m/s)",
              min = 0, max = 50, value = 10, step = 1),
  numericInput("maxvRot", "Max rotational velocity (rad/s)",
              min = 0, max = 5000, value = 300, step = 15),
  numericInput("nPasses", "Number of passes",
              min = 1, max = 10, value = 1, step = 1),
  numericInput("plotheight", "Plot Height",
            min = 50, max = Inf, value = 500, step = 50),
)

renderPlot({
  data <- getTrackerDataForTrial(input$participant, input$TrialNumber)
  data <- filterAllData(data, input$maxv, input$maxvRot, input$nPasses)
  
  # Create plot
  return(plotData2D(data, input$xplot, input$yplot))
}, height = reactive(input$plotheight))

plotData2D <- function(data, x_axis, y_axis) {
  # Filter out the desired time to plot
  data <- data[data$time >= input$start & data$time <= input$end, ]
  
  p <- ggplot(data, aes_string(x = x_axis, y = y_axis)) +
    geom_line(color = "black") +
    geom_point(aes_string(color = "artifact"), data = data[data$artifact != "none", ]) +
    scale_color_manual(values = c("LeftFoot" = "red", "RightFoot" = "blue", "TreadmillLeft" = "green", "TreadmillRight" = "purple")) +
    theme_minimal()

  return(p)
}
```

## Transform data
We also need to transform the data to the Lokomat reference frame.

### Find transformation matrix
First, we find the transformation matrix by using the two trackers next to the treadmill to identify the origin position and orientation.

Here:
- `x = left`
- `y = up`
- `z = front`

```{r}
quaternionToRotationMatrix <- function(q) {
    # Ensure the quaternion is normalized
    q <- q / sqrt(sum(q^2))
    
    w <- q[1]
    x <- q[2]
    y <- q[3]
    z <- q[4]

    # Compute the elements of the rotation matrix
    rotMatrix <- matrix(c(
        1 - 2 * y^2 - 2 * z^2, 2 * x * y - 2 * z * w, 2 * x * z + 2 * y * w,
        2 * x * y + 2 * z * w, 1 - 2 * x^2 - 2 * z^2, 2 * y * z - 2 * x * w,
        2 * x * z - 2 * y * w, 2 * y * z + 2 * x * w, 1 - 2 * x^2 - 2 * y^2
    ), nrow = 3, byrow = TRUE)

    # Append a fourth row and column for homogeneous coordinates
    rotMatrix <- rbind(rotMatrix, c(0, 0, 0))
    rotMatrix <- cbind(rotMatrix, c(0, 0, 0, 1))

    return(rotMatrix)
}

averageQuaternion <- function(quaternions) {
  # Ensure all quaternions are normalized
  normalizedQuaternions <- t(apply(quaternions, 1, function(q) {
    q / sqrt(sum(q^2))
  }))

  # Calculate the weighted average
  avgQ <- colMeans(normalizedQuaternions)

  # Normalize the result
  avgQ <- avgQ / sqrt(sum(avgQ^2))

  return(avgQ)
}

vectorCrossProduct <- function(a, b) {
  c(
    a[2]*b[3] - a[3]*b[2],
    a[3]*b[1] - a[1]*b[3],
    a[1]*b[2] - a[2]*b[1]
  )
}

calculateTransformationMatrix <- function(trackerData) {
  # Calculate the average position of the trackers over the first x frames
  frames <- 1:length(trackerData[,1])
  avgLeftPos <- colMeans(trackerData[frames, c("TreadmillLeft.pos.x", "TreadmillLeft.pos.y", "TreadmillLeft.pos.z")])
  avgRightPos <- colMeans(trackerData[frames, c("TreadmillRight.pos.x", "TreadmillRight.pos.y", "TreadmillRight.pos.z")])

  # X Axis: Line between two trackers
  xAxis <- avgRightPos - avgLeftPos
  xAxis <- xAxis / sqrt(sum(xAxis^2))  # Normalize
  
  # Y Axis: Average 'up' direction of the trackers
  # Assuming 'up' is represented by the y-component of the quaternion rotation
  meanQuatLeft <- colMeans(trackerData[frames, c("TreadmillLeft.rot.w", "TreadmillLeft.rot.x", "TreadmillLeft.rot.y", "TreadmillLeft.rot.z")])
  leftUp <- quaternionToRotationMatrix(meanQuatLeft)[2, 1:3] # z axis is up
  meanQuatRight <- colMeans(trackerData[frames, c("TreadmillRight.rot.w", "TreadmillRight.rot.x", "TreadmillRight.rot.y", "TreadmillRight.rot.z")])
  rightUp <- quaternionToRotationMatrix(meanQuatRight)[2, 1:3]
  yAxis <- (leftUp + rightUp) / 2
  yAxis <- yAxis / sqrt(sum(yAxis^2))  # Normalize
  
  #yAxis <- c(0,1,0)
  # Z Axis: Orthogonal to X and Y
  zAxis <- vectorCrossProduct(yAxis, xAxis)
  zAxis <- zAxis / sqrt(sum(zAxis^2))  # Normalize

  # Create the rotation matrix
  rotationMatrix <- rbind(xAxis, zAxis, yAxis) # we swap y and z, I think because LH vs RH coordinate frame
  print(rotationMatrix)
  #rotationMatrix <- rbind(c(1,0,0), c(0,1,0), c(0,0,1))
  
  # Ensure rotation matrix is 3x3
  rotationMatrix <- matrix(rotationMatrix, nrow = 3, ncol = 3)
  # Create the translation matrix
  translationMatrix <- diag(4)
  translationMatrix[1:3, 4] <- -colMeans(rbind(avgLeftPos, avgRightPos))

  # Combine the rotation and translation into a single transformation matrix
  transformationMatrix <- rbind(cbind(rotationMatrix, translationMatrix[1:3,4]), c(0, 0, 0, 1))

  return(transformationMatrix)
}

# Example usage with your tracker data
tmatrix <- calculateTransformationMatrix(filteredData)
#tmatrix
```

### Transformed the data

```{r}
transformTrackerData <- function(data, trackerName, tmatrix) {
  pattern <- paste0("^", trackerName) # get just the position data
  trackerCols <- grep(pattern, colnames(data), value = TRUE) # Get the column names that match the pattern
  posCols <- grep(".pos", trackerCols, value = TRUE) # only the position columns (these are used to get the velocity)
  quatCols <- grep(".rot", trackerCols, value = TRUE) # Quaternion columns
  
  # Transform function
  transformedData <- t(apply(data[, posCols], 1, function(pos) {
          posHomogeneous <- c(pos, 1)  # Add a 1 for homogeneous coordinates
          transformedPos <- tmatrix %*% posHomogeneous  # Apply the transformation
          return(transformedPos[1:3])
          }))
  
  data[, posCols] <- transformedData
  
  return(data)
}

# Example usage
#transformTrackerData(trackerData, "LeftFoot", tmatrix)

transformAllData <- function(data, tmatrix) {
  data <- transformTrackerData(data, "LeftFoot", tmatrix)
  data <- transformTrackerData(data, "RightFoot", tmatrix)
  data <- transformTrackerData(data, "TreadmillLeft", tmatrix)
  data <- transformTrackerData(data, "TreadmillRight", tmatrix)
  return(data)
}

# Usage example:
transformedData <- transformAllData(filteredData, tmatrix)
```


### 3D Plot

First thing to do is check if our transform works. We do this by making a 3D plot that shows our new reference frame. 

```{r,echo=FALSE}
tfGizmo <- function(origin, len, rotationMatrix = diag(4)){
  rotationMatrix <- rotationMatrix[1:3,1:3] # we only use the rotation
  xAxis <- as.vector(rotationMatrix %*% c(len, 0, 0))
  yAxis <- as.vector(rotationMatrix %*% c(0, len, 0))
  zAxis <- as.vector(rotationMatrix %*% c(0, 0, len))
  arrow3d(origin, origin + xAxis, col="red")   # X-axis
  arrow3d(origin, origin + yAxis, col="green") # Y-axis
  arrow3d(origin, origin + zAxis, col="blue")  # Z-axis
}

drawMeanAxes <- function(data, trackerName){
  posCols <- grep(paste0(trackerName,".pos"), colnames(data), value = TRUE)
  rotCols <- grep(paste0(trackerName,".rot"), colnames(data), value = TRUE)
  
  # Calculate the means
  meanPos <- sapply(data[, posCols], mean, na.rm = TRUE)
  meanQuaternion <- sapply(data[, rotCols], mean, na.rm = TRUE) # this should be done with slerp but for now this is fine.
  
  points3d(meanPos[1], meanPos[2], meanPos[3], col = "red", size = 5)
  tfGizmo(meanPos, 0.1, quaternionToRotationMatrix(meanQuaternion))
}

renderRglwidget({
  # Clear existing rgl plot
  rgl::rgl.clear()
  # Set uniform aspect ratio
  rgl::aspect3d(1, 1, 1)
  # Get data
  data <- getTrackerDataForTrial(input$participant, input$TrialNumber)
  data <- filterAllData(data, input$maxv, 1)
  tmatrix <- calculateTransformationMatrix(data)
  data <- transformAllData(data, tmatrix)
  
  # Add origin arrows
  tfGizmo(c(0,0,0), 0.2)
  
  # Create your 3D plot
  leftFootCols <- grep("LeftFoot.pos", colnames(trackerData), value = TRUE)
  lines3d(data[[leftFootCols[1]]], data[[leftFootCols[2]]], data[[leftFootCols[3]]], color="black") 
  
  drawMeanAxes(data, "TreadmillLeft")
  drawMeanAxes(data, "TreadmillRight")
  
  # Return the rgl widget
  rglwidget()
})

```

# Plotting

Click here to save the figures
```{r, echo=FALSE}
inputPanel(
  actionButton("save", "Save figures")
)
```




## Plot trajectories


